\begin{abstract}
As businesses seek to monetize their data, they are leveraging Web-based delivery mechanisms to provide publicly available data sources. Also, as analytics becomes a central part of many business functions such as customer segmentation, competitive intelligence and fraud detection, many businesses are seeking to enrich their internal data records with data from these data sources. As the number of sources with varying degrees of accuracy and quality proliferate, it is a non-trivial task to effectively select which sources to use for a particular enrichment task. The old model of statically buying data from one or two providers becomes inefficient because of the rapid growth of new forms of useful data such as social media and the lack of dynamism to plug sources in and out. In this paper, we present the data enrichment framework, a tool that uses data mining and other semantic techniques to automatically guide the selection of sources. The enrichment framework also monitors the quality of the data sources and automatically penalizes sources that continue to return low quality results.
\end{abstract}

\section{Introduction}

As enterprises become more data and analytics driven, many businesses are seeking to enrich their internal data records with data from data sources available on the Web. Consider the example, where the consumer database of a company might have the name and address of its consumers.  Being able to use publicly available data sources such as LinkedIn, White Pages and Facebook to find information such as employment details and interests, can help the company collect additional features for tasks such as customer segmentation. Currently, this is done in a static fashion where a business buys data from one or two sources and statically integrates with their internal data. However, this approach has the following shortcomings:
\begin{enumerate}
  \item \textbf{Inconsistencies in input data}: It is not uncommon to have different set of missing attributes across records in the input data. For example, for some consumers, the street address information might be missing and for others, information about the city might be missing. To address this issue, one must be able to select the data sources at a granular level, based on the input data that is available and the data sources that can be used.
   \item \textbf{Quality of a data source may vary, depending on the input data}: Calling a data source with some missing values (even though they may not be mandatory), can result in poor quality results. In such a scenario, one must be able to find the missing values, before calling the source or use an alternative.
\end{enumerate}
In this paper, we present an overview of a data enrichment framework which attempts to automate many sub-tasks of data enrichment. The framework uses a combination of data mining and semantic technologies to automate various tasks such as calculating which attributes are more important than others for source selection, selecting sources based on information available about a data record and past performance of the sources, using multiple sources to reinforce low confidence values, monitoring the utility of sources, as well as adaptation of sources based on past performance. The data enrichment framework makes the following contributions:
\begin{enumerate}
  \item \textbf{Dynamic selection of data sources}: We have developed a novel approach to automatically select the appropriate sequence of data sources to call, based on the available data.
  \item \textbf{Automated assessment of data source utility}: Our data enrichment algorithm measures the quality of the output of a data source and its overall utility to the enrichment process.
  \item \textbf{Automated adaptation of data source usage}: Using the data availability and utility scores from prior invocations, the enrichment framework penalized or rewards data sources, which affects how often they are selected.
\end{enumerate}


